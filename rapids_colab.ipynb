{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rapids-colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjotelu/rapids/blob/master/rapids_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfLT2i0MLyD",
        "colab_type": "text"
      },
      "source": [
        "# Environment Sanity Check #\n",
        "\n",
        "Click the _Runtime_ dropdown at the top of the page, then _Change Runtime Type_ and confirm the instance type is _GPU_.\n",
        "\n",
        "Check the output of `!nvidia-smi` to make sure you've been allocated a Tesla T4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0C8IV5TQnjN",
        "colab_type": "code",
        "outputId": "1c787b08-6525-45e0-b2d0-a2bcfc8e85aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May 24 08:01:33 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik8Wv2K0uDfx",
        "colab_type": "code",
        "outputId": "0ed76728-4e7d-4efe-8412-583e4060ee10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pynvml\n",
        "\n",
        "pynvml.nvmlInit()\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "device_name = pynvml.nvmlDeviceGetName(handle)\n",
        "\n",
        "if device_name != b'Tesla K80':\n",
        "  raise Exception(\"\"\"\n",
        "    Unfortunately this instance does not have a T4 GPU.\n",
        "    \n",
        "    Please make sure you've configured Colab to request a GPU instance type.\n",
        "    \n",
        "    Sometimes Colab allocates a Tesla K80 instead of a T4. Resetting the instance.\n",
        "\n",
        "    If you get a K80 GPU, try Runtime -> Reset all runtimes...\n",
        "  \"\"\")\n",
        "else:\n",
        "  print('Woo! You got the right kind of GPU!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Woo! You got the right kind of GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtNdk7PSafKP",
        "colab_type": "text"
      },
      "source": [
        "#Setup:\n",
        "\n",
        "1. Install most recent Miniconda release compatible with Google Colab's Python install  (3.6.7)\n",
        "2. Install RAPIDS libraries\n",
        "3. Set necessary environment variables\n",
        "4. Copy RAPIDS .so files into current working directory, a workaround for conda/colab interactions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0jdXBRiDSzj",
        "colab_type": "code",
        "outputId": "a2fc0d5f-a055-448d-f5c7-1c1d42a6ebb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        }
      },
      "source": [
        "# intall miniconda\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "# install RAPIDS packages\n",
        "!conda install -q -y --prefix /usr/local -c conda-forge \\\n",
        "  -c rapidsai-nightly/label/cuda10.0 -c nvidia/label/cuda10.0 \\\n",
        "  cudf cuml\n",
        "\n",
        "# set environment vars\n",
        "import sys, os, shutil\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "\n",
        "# copy .so files to current working dir\n",
        "for fn in ['libcudf.so', 'librmm.so']:\n",
        "  shutil.copy('/usr/local/lib/'+fn, os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-24 08:01:51--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "\r          Miniconda   0%[                    ]       0  --.-KB/s               \r         Miniconda3  48%[========>           ]  27.26M   134MB/s               \rMiniconda3-4.5.4-Li 100%[===================>]  55.76M   145MB/s    in 0.4s    \n",
            "\n",
            "2019-05-24 08:01:51 (145 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "Python 3.6.5 :: Anaconda, Inc.\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Solving environment: ...working... "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oOCJ4NYMjY7",
        "colab_type": "text"
      },
      "source": [
        "# cuDF and cuML Examples #\n",
        "\n",
        "Now you can run code! \n",
        "\n",
        "What follows are basic examples where all processing takes place on the GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V38dg-oUJtEO",
        "colab_type": "text"
      },
      "source": [
        "#[cuDF](https://github.com/rapidsai/cudf)#\n",
        "\n",
        "Load a dataset into a GPU memory resident DataFrame and perform a basic calculation.\n",
        "\n",
        "Everything from CSV parsing to calculating tip percentage and computing a grouped average is done on the GPU.\n",
        "\n",
        "_Note_: You must import nvstrings and nvcategory before cudf, else you'll get errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwaJSKuswsNi",
        "colab_type": "code",
        "outputId": "ba7cb330-1733-41d9-8c07-6e313c329160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import nvstrings, nvcategory, cudf\n",
        "import io, requests\n",
        "\n",
        "# download CSV file from GitHub\n",
        "url=\"https://github.com/plotly/datasets/raw/master/tips.csv\"\n",
        "content = requests.get(url).content.decode('utf-8')\n",
        "\n",
        "# read CSV from memory\n",
        "tips_df = cudf.read_csv(io.StringIO(content))\n",
        "tips_df['tip_percentage'] = tips_df['tip']/tips_df['total_bill']*100\n",
        "\n",
        "# display average tip by dining party size\n",
        "print(tips_df.groupby('size').tip_percentage.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size\n",
            "1     21.72920154872781\n",
            "2    16.571919173482893\n",
            "3    15.215685473711831\n",
            "4    14.594900639351332\n",
            "5    14.149548965142023\n",
            "6    15.622920072028379\n",
            "Name: tip_percentage, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul3UZJdUJqlT",
        "colab_type": "text"
      },
      "source": [
        "#[cuML](https://github.com/rapidsai/cuml)#\n",
        "\n",
        "This snippet loads a \n",
        "\n",
        "As above, all calculations are performed on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCE8WhO3HpL_",
        "colab_type": "code",
        "outputId": "cb5a0ecf-7902-4c9a-8da3-d00356542f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import cuml\n",
        "\n",
        "# Create and populate a GPU DataFrame\n",
        "df_float = cudf.DataFrame()\n",
        "df_float['0'] = [1.0, 2.0, 5.0]\n",
        "df_float['1'] = [4.0, 2.0, 1.0]\n",
        "df_float['2'] = [4.0, 2.0, 1.0]\n",
        "\n",
        "# Setup and fit clusters\n",
        "dbscan_float = cuml.DBSCAN(eps=1.0, min_samples=1)\n",
        "dbscan_float.fit(df_float)\n",
        "\n",
        "print(dbscan_float.labels_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0\n",
            "1    1\n",
            "2    2\n",
            "dtype: int32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlsyk9m9NN2K",
        "colab_type": "text"
      },
      "source": [
        "# Next Steps #\n",
        "\n",
        "For an overview of how you can access and work with your own datasets in Colab, check out [this guide](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92).\n",
        "\n",
        "For more RAPIDS examples, check out our RAPIDS notebooks repos:\n",
        "1. https://github.com/rapidsai/notebooks\n",
        "2. https://github.com/rapidsai/notebooks-extended"
      ]
    }
  ]
}